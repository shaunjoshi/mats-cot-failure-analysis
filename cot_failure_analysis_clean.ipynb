{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the data:\n",
    "that was saved from data_generation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill as pickle\n",
    "\n",
    "try:\n",
    "    with open(\"model_answers_fixed.pkl\", \"rb\") as f:\n",
    "        loaded_model_answers = pickle.load(f)\n",
    "\n",
    "    print(\"✅ Successfully loaded the fixed pickle file!\")\n",
    "    print(f\"Loaded object type: {type(loaded_model_answers)}\")  # Should print <class 'dict'>\n",
    "except Exception as e:\n",
    "    print(\"⚠️ Error while loading:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill as pickle\n",
    "\n",
    "try:\n",
    "    with open(\"model_answers_fixed_two.pkl\", \"rb\") as f:\n",
    "        loaded_model_answers2 = pickle.load(f)\n",
    "\n",
    "    print(\"✅ Successfully loaded the fixed pickle file!\")\n",
    "    print(f\"Loaded object type: {type(loaded_model_answers)}\")  # Should print <class 'dict'>\n",
    "except Exception as e:\n",
    "    print(\"⚠️ Error while loading:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_answers.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_answers2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dictionaries_incrementing_keys(dict1, dict2):\n",
    "    \"\"\"Merges two dictionaries, incrementing keys of the second dictionary to prevent overlap.\"\"\"\n",
    "    merged_dict = dict1.copy()  # Start with the first dictionary\n",
    "    \n",
    "    # Find the highest existing key in dict1\n",
    "    max_key = max(dict1.keys(), default=-1) + 1  \n",
    "\n",
    "    # Add entries from dict2, incrementing keys\n",
    "    for key, value in dict2.items():\n",
    "        merged_dict[max_key] = value\n",
    "        max_key += 1  # Ensure unique keys\n",
    "\n",
    "    return merged_dict\n",
    "\n",
    "\n",
    "# Merge with incremented indices\n",
    "merged_model_answers = merge_dictionaries_incrementing_keys(loaded_model_answers, loaded_model_answers2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model_answers.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate the correct and incorrect paths\n",
    "Note there is some randomness here because I deliberately only select one path (out of 3) for each question, and I select a random incorrect path\n",
    "I basically give the model 3 tries to get it right and use a parsing library that sometimes gets it wrong, so I bias towards high-confidence incorrect examples and correct examples that the parser found in at least one try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "correct_paths = []\n",
    "incorrect_paths = []\n",
    "\n",
    "# Iterate through each key-value pair\n",
    "for key, value_dict in merged_model_answers.items():\n",
    "    try:\n",
    "        # Ensure value_dict is a dictionary and contains `correctness_list`\n",
    "        if isinstance(value_dict, dict) and 'correctness_list' in value_dict:\n",
    "            correctness_list = value_dict['correctness_list']\n",
    "            correct_indices = [idx for idx, correctness in enumerate(correctness_list) if correctness == 1]\n",
    "\n",
    "            if correct_indices:\n",
    "                # Pick the first correct path\n",
    "                idx = correct_indices[0]\n",
    "                correct_paths.append(value_dict[idx].get('raw_model_answer', ''))\n",
    "            else:\n",
    "                # If all are incorrect, pick a random incorrect path\n",
    "                incorrect_indices = [idx for idx in range(len(correctness_list)) if idx in value_dict]\n",
    "                if incorrect_indices:\n",
    "                    idx = random.choice(incorrect_indices)\n",
    "                    incorrect_paths.append(value_dict[idx].get('raw_model_answer', ''))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Skipping key {key}: Could not process value. Error: {e}\")\n",
    "\n",
    "# Display results\n",
    "print(\"Correct Paths:\", correct_paths[:3])  # Print first 3 for verification\n",
    "print(\"Incorrect Paths:\", incorrect_paths[:3])  # Print first 3 for verification\n",
    "\n",
    "print(\"Correct rate: \",len(correct_paths)/(len(correct_paths) + len(incorrect_paths)))\n",
    "print(\"Correct rate: \",len(incorrect_paths)/(len(correct_paths) + len(incorrect_paths)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(len(correct_paths))\n",
    "print(len(incorrect_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets split our incorrect and correct paths into thoughts and compute iterative embeddings for each thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load embedding model\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def split_into_thoughts(paths, delimiter=\"\\n\"):\n",
    "    \"\"\"\n",
    "    Splits each CoT response into a list of thoughts based on the given delimiter.\n",
    "    \n",
    "    Parameters:\n",
    "    - paths (list of str): Each entry is a CoT response as a single string.\n",
    "\n",
    "    Returns:\n",
    "    - list of list of str: Each CoT response split into separate thoughts.\n",
    "    \"\"\"\n",
    "    return [path.split(delimiter) for path in paths]\n",
    "\n",
    "def compute_thoughtwise_embedding_differences_aggregated(reasoning_paths):\n",
    "    \"\"\"\n",
    "    Computes thought-to-thought embedding similarity across multiple completions,\n",
    "    while aggregating results across different questions.\n",
    "\n",
    "    Parameters:\n",
    "    - reasoning_paths (list of list of str): Each entry is a CoT path, which is a list of thought.\n",
    "\n",
    "    Returns:\n",
    "    - mean_similarities (list of float): Mean thoughtwise thought-to-thought similarity scores.\n",
    "    - std_similarities (list of float): Standard deviation of thoughtwise similarities (for variability analysis).\n",
    "    \"\"\"\n",
    "    if not reasoning_paths:\n",
    "        print(\"⚠️ Warning: Received an empty list of reasoning paths.\")\n",
    "        return [], []\n",
    "\n",
    "    max_thoughts = max(len(path) for path in reasoning_paths)\n",
    "    all_similarities = [[] for _ in range(max_thoughts - 1)]  # Store similarities for each thought index\n",
    "\n",
    "    print(f\"Debugging: Max Thoughts Across Paths: {max_thoughts}\")\n",
    "    print(f\"Debugging: Number of Reasoning Paths: {len(reasoning_paths)}\")\n",
    "\n",
    "    for path_idx, path in enumerate(reasoning_paths):\n",
    "        print(f\"\\nProcessing path {path_idx + 1}/{len(reasoning_paths)} with {len(path)} thoughts\")\n",
    "\n",
    "\n",
    "        for thought in range(1, len(path)):  # Start at thought 1 to compare with thought 0\n",
    "            prev_thought_text = path[thought - 1].strip()\n",
    "            curr_thought_text = path[thought].strip()\n",
    "\n",
    "            if not prev_thought_text or not curr_thought_text:\n",
    "                #print(f\"⚠️ thought {thought}: Skipping empty thought in path {path_idx + 1}\")\n",
    "                continue  # Skip empty thoughts\n",
    "\n",
    "            # Compute embeddings\n",
    "            prev_thought_embedding = embedder.encode(prev_thought_text, convert_to_tensor=True)\n",
    "            curr_thought_embedding = embedder.encode(curr_thought_text, convert_to_tensor=True)\n",
    "\n",
    "            # Compute cosine similarity\n",
    "            similarity = torch.nn.functional.cosine_similarity(prev_thought_embedding, curr_thought_embedding, dim=0).item()\n",
    "            all_similarities[thought - 1].append(similarity)\n",
    "\n",
    "    # Aggregate mean and std similarity across different paths for each thought index\n",
    "    mean_similarities = [np.mean(sim) if sim else 0 for sim in all_similarities]\n",
    "    std_similarities = [np.std(sim) if sim else 0 for sim in all_similarities]\n",
    "\n",
    "    print(f\"Debugging: Computed {len(mean_similarities)} mean similarities and {len(std_similarities)} standard deviations\")\n",
    "\n",
    "    return mean_similarities, std_similarities\n",
    "\n",
    "# Example reasoning paths (for debugging)\n",
    "\n",
    "\n",
    "# Split responses into thoughtwise reasoning paths\n",
    "correct_paths_split = split_into_thoughts(correct_paths)\n",
    "wrong_paths_split = split_into_thoughts(incorrect_paths)\n",
    "\n",
    "# Compute aggregated thoughtwise similarity differences for correct and wrong CoTs\n",
    "mean_thoughtwise_correct, std_thoughtwise_correct = compute_thoughtwise_embedding_differences_aggregated(correct_paths_split)\n",
    "mean_thoughtwise_wrong, std_thoughtwise_wrong = compute_thoughtwise_embedding_differences_aggregated(wrong_paths_split)\n",
    "\n",
    "# Debugging: Check if similarity lists have unexpected lengths\n",
    "print(f\"Debugging: Length of Correct Similarities: {len(mean_thoughtwise_correct)}\")\n",
    "print(f\"Debugging: Length of Wrong Similarities: {len(mean_thoughtwise_wrong)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 **Plot thoughtwise similarity**\n",
    "if mean_thoughtwise_correct and mean_thoughtwise_wrong:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.plot(range(1, len(mean_thoughtwise_correct) + 1), mean_thoughtwise_correct, label=\"Correct Paths\", color=\"green\")\n",
    "    plt.fill_between(range(1, len(mean_thoughtwise_correct) + 1), \n",
    "                     np.array(mean_thoughtwise_correct) - np.array(std_thoughtwise_correct),\n",
    "                     np.array(mean_thoughtwise_correct) + np.array(std_thoughtwise_correct),\n",
    "                     color=\"green\", alpha=0.2)\n",
    "\n",
    "    plt.plot(range(1, len(mean_thoughtwise_wrong) + 1), mean_thoughtwise_wrong, label=\"Wrong Paths\", color=\"red\")\n",
    "    plt.fill_between(range(1, len(mean_thoughtwise_wrong) + 1), \n",
    "                     np.array(mean_thoughtwise_wrong) - np.array(std_thoughtwise_wrong),\n",
    "                     np.array(mean_thoughtwise_wrong) + np.array(std_thoughtwise_wrong),\n",
    "                     color=\"red\", alpha=0.2)\n",
    "\n",
    "    plt.xlabel(\"Thought Number\")\n",
    "    plt.ylabel(\"Thought-to-Thought Cosine Similarity\")\n",
    "    plt.title(\"Thought-to-Thought Similarity: Correct vs. Wrong Paths (Aggregated)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"⚠️ Warning: Thoughtwise similarity data is empty, cannot plot results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MATH-500 dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "print(\"📥 Loading MATH-500 dataset...\")\n",
    "dataset = load_dataset(\"HuggingFaceH4/MATH-500\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In the cell below I compute the paths grouped by difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# Extract problem difficulty levels (1 to 5)\n",
    "problem_difficulties = dataset['test']['level']\n",
    "\n",
    "# Initialize dictionaries for correct and incorrect paths grouped by difficulty\n",
    "paths_by_difficulty_correct = {level: [] for level in range(1, 6)}\n",
    "paths_by_difficulty_wrong = {level: [] for level in range(1, 6)}\n",
    "\n",
    "# Populate correct and incorrect paths ensuring **only one per item**\n",
    "for key, value_dict in merged_model_answers.items():\n",
    "    try:\n",
    "        if isinstance(value_dict, dict) and 'correctness_list' in value_dict:\n",
    "            correctness_list = value_dict['correctness_list']\n",
    "\n",
    "            if key >= len(problem_difficulties):  \n",
    "                print(f\"⚠️ Skipping key {key}: No matching difficulty level found.\")\n",
    "                continue\n",
    "\n",
    "            difficulty_level = problem_difficulties[key]  # Get corresponding difficulty\n",
    "\n",
    "            # Find correct paths\n",
    "            correct_indices = [idx for idx, correctness in enumerate(correctness_list) if correctness == 1]\n",
    "\n",
    "            if correct_indices:\n",
    "                # Pick only the first correct path\n",
    "                idx = correct_indices[0]\n",
    "                raw_model_answer = value_dict[idx].get('raw_model_answer', '')\n",
    "                paths_by_difficulty_correct[difficulty_level].append(raw_model_answer)\n",
    "            else:\n",
    "                # If all are incorrect, select one random incorrect path\n",
    "                incorrect_indices = [idx for idx in range(len(correctness_list)) if idx in value_dict]\n",
    "                if incorrect_indices:\n",
    "                    idx = random.choice(incorrect_indices)\n",
    "                    raw_model_answer = value_dict[idx].get('raw_model_answer', '')\n",
    "                    paths_by_difficulty_wrong[difficulty_level].append(raw_model_answer)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Skipping key {key}: Could not process value. Error: {e}\")\n",
    "\n",
    "\n",
    "print(paths_by_difficulty_correct)\n",
    "print(paths_by_difficulty_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example data (replace with actual counts from your dataset)\n",
    "difficulty_levels = [1, 2, 3, 4, 5]\n",
    "correct_counts = [len(paths_by_difficulty_correct[level]) for level in difficulty_levels]\n",
    "incorrect_counts = [len(paths_by_difficulty_wrong[level]) for level in difficulty_levels]\n",
    "\n",
    "# Set up bar width and positions\n",
    "bar_width = 0.35\n",
    "x = np.arange(len(difficulty_levels))\n",
    "\n",
    "# Create the bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.bar(x - bar_width/2, correct_counts, bar_width, label='Correct', color='green')\n",
    "ax.bar(x + bar_width/2, incorrect_counts, bar_width, label='Incorrect', color='red')\n",
    "\n",
    "# Labels and formatting\n",
    "ax.set_xlabel('Difficulty Level')\n",
    "ax.set_ylabel('Number of Answers')\n",
    "ax.set_title('Number of Correct and Incorrect Answers per Difficulty Level')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(difficulty_levels)\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In the cell below I look for any interesting trends regarding the path length or branching factor\n",
    "- Didnt find anything interesting here worth reporting, the average path length is longer for incorrect rather than correct solutions but this is trivial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute Path Lengths and Branching Factors**\n",
    "def compute_path_lengths(paths):\n",
    "    \"\"\"Computes the number of steps in each path.\"\"\"\n",
    "    return [len(path) for path in paths]\n",
    "\n",
    "def compute_branching_factor(paths):\n",
    "    \"\"\"Computes the unique step transitions per reasoning step.\"\"\"\n",
    "    max_steps = max(len(path) for path in paths) if paths else 0\n",
    "    stepwise_transitions = [defaultdict(int) for _ in range(max_steps)]\n",
    "\n",
    "    for path in paths:\n",
    "        for step_idx in range(len(path) - 1):  # Skip last step\n",
    "            transition = (path[step_idx], path[step_idx + 1])\n",
    "            stepwise_transitions[step_idx][transition] += 1\n",
    "\n",
    "    return [len(step.keys()) for step in stepwise_transitions if step]\n",
    "\n",
    "# Compute Metrics Across Difficulty Levels**\n",
    "difficulty_path_lengths_correct = {}\n",
    "difficulty_path_lengths_wrong = {}\n",
    "difficulty_branching_factors_correct = {}\n",
    "difficulty_branching_factors_wrong = {}\n",
    "\n",
    "for level in range(1, 6):  # Loop over difficulty levels 1 to 5\n",
    "    if paths_by_difficulty_correct[level]:\n",
    "        difficulty_path_lengths_correct[level] = compute_path_lengths(paths_by_difficulty_correct[level])\n",
    "        difficulty_branching_factors_correct[level] = compute_branching_factor(paths_by_difficulty_correct[level])\n",
    "    else:\n",
    "        difficulty_path_lengths_correct[level] = []\n",
    "\n",
    "\n",
    "    if paths_by_difficulty_wrong[level]:\n",
    "        difficulty_path_lengths_wrong[level] = compute_path_lengths(paths_by_difficulty_wrong[level])\n",
    "        difficulty_branching_factors_wrong[level] = compute_branching_factor(paths_by_difficulty_wrong[level])\n",
    "    else:\n",
    "        difficulty_path_lengths_wrong[level] = []\n",
    "        difficulty_branching_factors_wrong[level] = []\n",
    "        \n",
    "# Visualization**\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# **1️⃣ Path Lengths vs. Difficulty (Correct vs. Incorrect)**\n",
    "plt.subplot(1, 2, 1)\n",
    "mean_lengths_correct = [np.mean(difficulty_path_lengths_correct[level]) if difficulty_path_lengths_correct[level] else 0 for level in range(1, 6)]\n",
    "mean_lengths_wrong = [np.mean(difficulty_path_lengths_wrong[level]) if difficulty_path_lengths_wrong[level] else 0 for level in range(1, 6)]\n",
    "\n",
    "plt.plot(range(1, 6), mean_lengths_correct, marker=\"o\", linestyle=\"-\", color=\"green\", label=\"Correct Paths\")\n",
    "plt.plot(range(1, 6), mean_lengths_wrong, marker=\"o\", linestyle=\"-\", color=\"red\", label=\"Incorrect Paths\")\n",
    "\n",
    "plt.xlabel(\"Problem Difficulty (1 = Easy, 5 = Hard)\")\n",
    "plt.ylabel(\"Avg. Path Length (Steps)\")\n",
    "plt.title(\"Path Length vs. Problem Difficulty (Correct vs. Incorrect)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# **2️⃣ Branching Factor vs. Difficulty (Correct vs. Incorrect)**\n",
    "plt.subplot(1, 2, 2)\n",
    "mean_branching_correct = [np.mean(difficulty_branching_factors_correct[level]) if difficulty_branching_factors_correct[level] else 0 for level in range(1, 6)]\n",
    "mean_branching_wrong = [np.mean(difficulty_branching_factors_wrong[level]) if difficulty_branching_factors_wrong[level] else 0 for level in range(1, 6)]\n",
    "\n",
    "plt.plot(range(1, 6), mean_branching_correct, marker=\"o\", linestyle=\"-\", color=\"green\", label=\"Correct Paths\")\n",
    "plt.plot(range(1, 6), mean_branching_wrong, marker=\"o\", linestyle=\"-\", color=\"red\", label=\"Incorrect Paths\")\n",
    "\n",
    "plt.xlabel(\"Problem Difficulty (1 = Easy, 5 = Hard)\")\n",
    "plt.ylabel(\"Avg. Branching Factor\")\n",
    "plt.title(\"Branching Factor vs. Problem Difficulty (Correct vs. Incorrect)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In the cells below I compute what I did above but split for each difficulty\n",
    "There are no intersting trends and a bigram word model seems to simplistic to use as a measure compared to embeddings or entropy, these results were excluded from the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "def split_into_steps(path):\n",
    "    \"\"\"Splits a path into individual steps (assumes space-separated steps).\"\"\"\n",
    "    return path.split()\n",
    "\n",
    "def compute_path_lengths(paths):\n",
    "    \"\"\"Computes the length of each path (number of steps).\"\"\"\n",
    "    return [len(path) for path in paths]\n",
    "\n",
    "def remove_outliers(data):\n",
    "    \"\"\"Removes outliers using the Interquartile Range (IQR) method.\"\"\"\n",
    "    if not data:\n",
    "        return data  # Return empty list if no data is provided\n",
    "    \n",
    "    q1 = np.percentile(data, 25)  # First quartile (Q1)\n",
    "    q3 = np.percentile(data, 75)  # Third quartile (Q3)\n",
    "    iqr = q3 - q1  # Interquartile range\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "    return [x for x in data if lower_bound <= x <= upper_bound]\n",
    "\n",
    "def compute_branching_factor(paths):\n",
    "    \"\"\"Computes the average number of unique step transitions at each step.\"\"\"\n",
    "    if not paths:\n",
    "        return []\n",
    "    \n",
    "    max_steps = max(len(path) for path in paths)\n",
    "    stepwise_transitions = [defaultdict(int) for _ in range(max_steps)]\n",
    "\n",
    "    # Count unique transitions at each step\n",
    "    for path in paths:\n",
    "        for step_idx in range(len(path) - 1):  # Skip last step\n",
    "            transition = (path[step_idx], path[step_idx + 1])\n",
    "            stepwise_transitions[step_idx][transition] += 1\n",
    "\n",
    "    # Compute branching factor per step\n",
    "    return [len(step.keys()) for step in stepwise_transitions if step]\n",
    "\n",
    "# **1️⃣ Organize Paths by Difficulty Level**\n",
    "difficulty_levels = dataset['test']['level']  # Extract problem difficulties\n",
    "\n",
    "# Create separate dictionaries for correct and incorrect paths per difficulty level\n",
    "correct_paths_by_difficulty = {level: [] for level in range(1, 6)}\n",
    "wrong_paths_by_difficulty = {level: [] for level in range(1, 6)}\n",
    "\n",
    "# Assign one path per difficulty level\n",
    "for key, value_dict in merged_model_answers.items():\n",
    "    try:\n",
    "        if isinstance(value_dict, dict) and 'correctness_list' in value_dict:\n",
    "            correctness_list = value_dict['correctness_list']\n",
    "\n",
    "            if key >= len(difficulty_levels):\n",
    "                print(f\"⚠️ Skipping key {key}: No matching difficulty level found.\")\n",
    "                continue\n",
    "            \n",
    "            difficulty_level = difficulty_levels[key]  # Get corresponding difficulty level\n",
    "            correct_indices = [idx for idx, correctness in enumerate(correctness_list) if correctness == 1]\n",
    "\n",
    "            if correct_indices:\n",
    "                # Pick the first correct path and split into steps\n",
    "                idx = correct_indices[0]\n",
    "                path = value_dict[idx].get('raw_model_answer', '')\n",
    "                correct_paths_by_difficulty[difficulty_level].append(split_into_steps(path))\n",
    "            else:\n",
    "                # If all are incorrect, pick a random incorrect path and split into steps\n",
    "                incorrect_indices = [idx for idx in range(len(correctness_list)) if idx in value_dict]\n",
    "                if incorrect_indices:\n",
    "                    idx = random.choice(incorrect_indices)\n",
    "                    path = value_dict[idx].get('raw_model_answer', '')\n",
    "                    wrong_paths_by_difficulty[difficulty_level].append(split_into_steps(path))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Skipping key {key}: Could not process value. Error: {e}\")\n",
    "\n",
    "# **2️⃣ Compute Path Lengths and Branching Factors for Each Difficulty**\n",
    "filtered_path_lengths_correct = {}\n",
    "filtered_path_lengths_wrong = {}\n",
    "filtered_branching_factors_correct = {}\n",
    "filtered_branching_factors_wrong = {}\n",
    "\n",
    "for level in range(1, 6):\n",
    "    if correct_paths_by_difficulty[level]:\n",
    "        raw_lengths = compute_path_lengths(correct_paths_by_difficulty[level])\n",
    "        filtered_path_lengths_correct[level] = remove_outliers(raw_lengths)\n",
    "        filtered_branching_factors_correct[level] = compute_branching_factor(\n",
    "            [path for path in correct_paths_by_difficulty[level] if len(path) in filtered_path_lengths_correct[level]]\n",
    "        )\n",
    "    else:\n",
    "        filtered_path_lengths_correct[level] = []\n",
    "        filtered_branching_factors_correct[level] = []\n",
    "\n",
    "    if wrong_paths_by_difficulty[level]:\n",
    "        raw_lengths = compute_path_lengths(wrong_paths_by_difficulty[level])\n",
    "        filtered_path_lengths_wrong[level] = remove_outliers(raw_lengths)\n",
    "        filtered_branching_factors_wrong[level] = compute_branching_factor(\n",
    "            [path for path in wrong_paths_by_difficulty[level] if len(path) in filtered_path_lengths_wrong[level]]\n",
    "        )\n",
    "    else:\n",
    "        filtered_path_lengths_wrong[level] = []\n",
    "        filtered_branching_factors_wrong[level] = []\n",
    "\n",
    "# **3️⃣ Visualization**\n",
    "for level in range(1, 6):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # **1️⃣ Path Length Distribution for this Difficulty Level**\n",
    "    axes[0].hist(filtered_path_lengths_correct[level], bins=20, alpha=0.5, label=\"Correct\", color=\"blue\")\n",
    "    axes[0].hist(filtered_path_lengths_wrong[level], bins=20, alpha=0.5, label=\"Incorrect\", color=\"red\", linestyle=\"dashed\")\n",
    "\n",
    "    axes[0].set_xlabel(\"Path Length (Number of Words)\")\n",
    "    axes[0].set_ylabel(\"Frequency\")\n",
    "    axes[0].set_title(f\"Path Length Distribution - Level {level}\")\n",
    "    axes[0].legend()\n",
    "\n",
    "    # **2️⃣ Stepwise Branching Factor Trends for this Difficulty Level**\n",
    "    axes[1].plot(range(1, len(filtered_branching_factors_correct[level]) + 1), \n",
    "                 filtered_branching_factors_correct[level], \n",
    "                 marker=\"o\", linestyle=\"-\", label=\"Correct\", color=\"blue\")\n",
    "\n",
    "    axes[1].plot(range(1, len(filtered_branching_factors_wrong[level]) + 1), \n",
    "                 filtered_branching_factors_wrong[level], \n",
    "                 marker=\"x\", linestyle=\"--\", label=\"Incorrect\", color=\"red\")\n",
    "\n",
    "    axes[1].set_xlabel(\"Word Index\")\n",
    "    axes[1].set_ylabel(\"Branching Factor (Unique Transitions)\")\n",
    "    axes[1].set_title(f\"Wordwise Branching Factor Trends - Level {level}\")\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn umap-learn numpy==2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# At this point I wanted to try clustering techniques on the embeddings to see if I could get some interesting separation. In all fairness, I tried PCA+Kmeans, with no luck.\n",
    "However, ChatGpt recommended AgglomerativeClustering for the following reason:\n",
    "\n",
    "UMAP + Agglomerative Clustering more effectively captures non-linear reasoning patterns in Chain-of-Thought (CoT) analysis than PCA + K-Means. UMAP preserves local structure, maintaining similarity between correct and incorrect reasoning paths, while PCA’s linear assumptions may obscure key distinctions. Agglomerative Clustering adapts to hierarchical reasoning trajectories, distinguishing between premature convergence (closely clustered incorrect paths) and excessive exploration (widely dispersed incorrect paths), whereas K-Means imposes rigid clusters that may not align with natural failure modes.\n",
    "\n",
    "By revealing both local and global structure, UMAP + Agglomerative Clustering offers a more interpretable and flexible analysis of reasoning failures in language models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import umap\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load embedding model\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def get_embeddings(paths):\n",
    "    \"\"\"Generates sentence embeddings for a list of paths.\"\"\"\n",
    "    if not paths:\n",
    "        return np.array([])  # Return empty array if no paths available\n",
    "    \n",
    "    return np.array(embedder.encode(paths, convert_to_numpy=True))\n",
    "\n",
    "# Generate Embeddings for Correct and Incorrect Paths by Difficulty**\n",
    "correct_embeddings_by_difficulty = {}\n",
    "wrong_embeddings_by_difficulty = {}\n",
    "\n",
    "for level in range(1, 6):\n",
    "    correct_embeddings_by_difficulty[level] = get_embeddings(correct_paths_by_difficulty[level])\n",
    "    wrong_embeddings_by_difficulty[level] = get_embeddings(wrong_paths_by_difficulty[level])\n",
    "\n",
    "# Apply UMAP and Hierarchical Clustering for Each Difficulty Level**\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))  # 2 Rows, 3 Columns\n",
    "axes = axes.flatten()\n",
    "\n",
    "for level in range(1, 6):\n",
    "    ax = axes[level - 1]  # Select subplot\n",
    "    \n",
    "    # Combine embeddings for clustering\n",
    "    embeddings = []\n",
    "    correctness_labels = []\n",
    "\n",
    "    if correct_embeddings_by_difficulty[level].size > 0:\n",
    "        embeddings.append(correct_embeddings_by_difficulty[level])\n",
    "        correctness_labels.extend([\"Correct\"] * len(correct_embeddings_by_difficulty[level]))\n",
    "\n",
    "    if wrong_embeddings_by_difficulty[level].size > 0:\n",
    "        embeddings.append(wrong_embeddings_by_difficulty[level])\n",
    "        correctness_labels.extend([\"Incorrect\"] * len(wrong_embeddings_by_difficulty[level]))\n",
    "\n",
    "    if embeddings:\n",
    "        # Stack embeddings\n",
    "        embeddings = np.vstack(embeddings)\n",
    "        \n",
    "        # Apply UMAP**\n",
    "        umap_reducer = umap.UMAP(n_components=2, n_neighbors=15, min_dist=0.1, metric='cosine')\n",
    "        reduced_embeddings = umap_reducer.fit_transform(embeddings)\n",
    "\n",
    "        # Agglomerative Clustering**\n",
    "        clustering = AgglomerativeClustering(n_clusters=2)  # Try different numbers of clusters\n",
    "        cluster_labels = clustering.fit_predict(reduced_embeddings)\n",
    "\n",
    "        # Plot Clusters**\n",
    "        sns.scatterplot(x=reduced_embeddings[:, 0], y=reduced_embeddings[:, 1], hue=cluster_labels, palette=\"deep\", ax=ax)\n",
    "\n",
    "        ax.set_xlabel(\"UMAP Component 1\")\n",
    "        ax.set_ylabel(\"UMAP Component 2\")\n",
    "        ax.set_title(f\"UMAP + Hierarchical Clustering (Difficulty {level})\")\n",
    "\n",
    "# Remove last empty subplot (for 2x3 layout)\n",
    "fig.delaxes(axes[-1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import umap\n",
    "from scipy.spatial.distance import cdist\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load embedding model\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def get_embeddings(paths):\n",
    "    \"\"\"Generates embeddings for a list of paths.\"\"\"\n",
    "    if not paths:\n",
    "        return np.array([])  # Return empty array if no paths available\n",
    "    return np.array(embedder.encode(paths, convert_to_numpy=True))\n",
    "\n",
    "# **1️⃣ Generate Embeddings for Correct and Incorrect Paths by Difficulty**\n",
    "correct_embeddings_by_difficulty = {}\n",
    "wrong_embeddings_by_difficulty = {}\n",
    "\n",
    "for level in range(1, 6):\n",
    "    correct_embeddings_by_difficulty[level] = get_embeddings(correct_paths_by_difficulty[level])\n",
    "    wrong_embeddings_by_difficulty[level] = get_embeddings(wrong_paths_by_difficulty[level])\n",
    "\n",
    "# **2️⃣ Apply UMAP and Find Most Distant Correct-Incorrect Pairs**\n",
    "distant_examples = {}\n",
    "\n",
    "for level in range(1, 6):\n",
    "    correct_embeddings = correct_embeddings_by_difficulty[level]\n",
    "    wrong_embeddings = wrong_embeddings_by_difficulty[level]\n",
    "    correct_paths = correct_paths_by_difficulty[level]\n",
    "    wrong_paths = wrong_paths_by_difficulty[level]\n",
    "\n",
    "    if correct_embeddings.size > 0 and wrong_embeddings.size > 0:\n",
    "        # Stack embeddings separately for correct and incorrect paths\n",
    "        combined_embeddings = np.vstack([correct_embeddings, wrong_embeddings])\n",
    "        combined_labels = [\"Correct\"] * len(correct_embeddings) + [\"Incorrect\"] * len(wrong_embeddings)\n",
    "        combined_paths = correct_paths + wrong_paths  # Keep corresponding text paths\n",
    "\n",
    "        # **Apply UMAP**\n",
    "        umap_reducer = umap.UMAP(n_components=2, n_neighbors=15, min_dist=0.1, metric='cosine')\n",
    "        reduced_embeddings = umap_reducer.fit_transform(combined_embeddings)\n",
    "\n",
    "        # **Separate Correct and Incorrect UMAP-Reduced Embeddings**\n",
    "        correct_indices = np.array([i for i, label in enumerate(combined_labels) if label == \"Correct\"])\n",
    "        incorrect_indices = np.array([i for i, label in enumerate(combined_labels) if label == \"Incorrect\"])\n",
    "\n",
    "        reduced_correct = reduced_embeddings[correct_indices]\n",
    "        reduced_incorrect = reduced_embeddings[incorrect_indices]\n",
    "\n",
    "        # **Compute Pairwise Distances Between Correct and Incorrect Embeddings**\n",
    "        distance_matrix = cdist(reduced_correct, reduced_incorrect, metric=\"euclidean\")\n",
    "\n",
    "        # **Find the Most Distant Correct-Incorrect Pair**\n",
    "        i, j = np.unravel_index(np.argmax(distance_matrix), distance_matrix.shape)\n",
    "        correct_index = correct_indices[i]\n",
    "        incorrect_index = incorrect_indices[j]\n",
    "\n",
    "        distant_examples[level] = (combined_paths[correct_index], combined_paths[incorrect_index])\n",
    "\n",
    "# **3️⃣ Print the Most Distant Correct vs. Incorrect Paths for Each Difficulty Level**\n",
    "for level, (correct_path, incorrect_path) in distant_examples.items():\n",
    "    print(f\"\\n### Difficulty {level} - Most Distant Correct vs. Incorrect Paths ###\")\n",
    "    print(\"\\nCorrect Example:\\n\", correct_path)\n",
    "    print(\"\\nIncorrect Example:\\n\", incorrect_path)\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distance in embedding space can be explained by differences in problem type, reasoning structure, and clarity between the correct and incorrect paths.\n",
    "\n",
    "### 1 Different problem types\n",
    "Example (Difficulty 1):\n",
    "Correct Path: Computes the modular inverse of 997 mod 1000, using the Extended Euclidean Algorithm.\n",
    "Incorrect Path: Solves a completely different algebraic problem involving systems of equations with three variables.\n",
    "Why They're Far Apart: These problems require entirely different mathematical approaches—modular arithmetic vs. polynomial equation solving—so embeddings naturally separate them.\n",
    "\n",
    "### 2️ Stepwise vs. Exploratory Reasoning\n",
    "Example (Difficulty 3):\n",
    "Correct Path: Methodically applies trigonometric identities to find tan(A) in a right triangle.\n",
    "Incorrect Path: Attempts to simplify a sum involving roots of unity, but instead of following a structured method, the reasoning jumps around leading to confusion.\n",
    "Why They're Far Apart: The correct path maintains logical consistency, while the incorrect path lacks focus, leading to higher entropy in reasoning flow.\n",
    "\n",
    "### 3 Lexical & Conceptual Drift (Precision vs. Redundant Exploration)\n",
    "Example (Difficulty 2):\n",
    "Correct Path: Uses geometric properties (Thales' theorem) to determine the measure of an angle in an inscribed triangle.\n",
    "Incorrect Path: Attempts to rotate a complex number 90 degrees, an unrelated problem with a different mathematical framework.\n",
    "Why They're Far Apart: Even though both involve geometry, the incorrect path introduces conceptually unrelated transformations, shifting its embedding further away from the structured solution.\n",
    "Conclusion\n",
    "\n",
    "The large distance in embedding space arises because:\n",
    "- Correct and incorrect paths often solve entirely different problems.\n",
    "- Correct paths follow structured, stepwise reasoning, while incorrect paths are more erratic.\n",
    "- Incorrect responses introduce unrelated concepts, causing conceptual drift in embeddings.\n",
    "\n",
    "Intuition: Since embeddings encode semantic and logical coherence, incorrect solutions that introduce topic shifts, redundant steps, or unrelated concepts naturally map further from structured, correct responses.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a bit naive but I want to compare the embeddings of incorrect and correct responses side by side to see if I can see any patterns:\n",
    "- the prediction is that correct might be tighter together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import umap\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load embedding model\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def get_embeddings(paths):\n",
    "    \"\"\"Generates sentence embeddings for a list of paths.\"\"\"\n",
    "    if not paths:\n",
    "        return np.array([])  \n",
    "    return np.array(embedder.encode(paths, convert_to_numpy=True))\n",
    "\n",
    "# Generate Embeddings for Correct and Incorrect Paths**\n",
    "correct_embeddings_by_difficulty = {}\n",
    "wrong_embeddings_by_difficulty = {}\n",
    "\n",
    "for level in range(1, 6):\n",
    "    correct_embeddings_by_difficulty[level] = get_embeddings(correct_paths_by_difficulty[level])\n",
    "    wrong_embeddings_by_difficulty[level] = get_embeddings(wrong_paths_by_difficulty[level])\n",
    "\n",
    "# Apply UMAP and Agglomerative Clustering for Both Correct & Incorrect Paths**\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 10))  # 2 Rows (Correct & Incorrect), 5 Columns (Difficulty Levels)\n",
    "\n",
    "clustered_responses = {\n",
    "    \"correct\": {},\n",
    "    \"incorrect\": {}\n",
    "}\n",
    "\n",
    "for level in range(1, 6):\n",
    "    for category, embeddings_dict, paths_dict, row_idx in [\n",
    "        (\"correct\", correct_embeddings_by_difficulty, correct_paths_by_difficulty, 0),\n",
    "        (\"incorrect\", wrong_embeddings_by_difficulty, wrong_paths_by_difficulty, 1),\n",
    "    ]:\n",
    "        ax = axes[row_idx, level - 1]  # Select subplot\n",
    "        paths = paths_dict[level]\n",
    "        embeddings = embeddings_dict[level]\n",
    "\n",
    "        if embeddings.size > 0:\n",
    "            # **Apply UMAP**\n",
    "            umap_reducer = umap.UMAP(n_components=2, n_neighbors=15, min_dist=0.1, metric='cosine')\n",
    "            reduced_embeddings = umap_reducer.fit_transform(embeddings)\n",
    "\n",
    "            # **Apply Agglomerative Clustering**\n",
    "            clustering = AgglomerativeClustering(n_clusters=3)\n",
    "            cluster_labels = clustering.fit_predict(reduced_embeddings)\n",
    "\n",
    "            # Store responses by cluster\n",
    "            clustered_responses[category][level] = {i: [] for i in range(3)}\n",
    "            for idx, label in enumerate(cluster_labels):\n",
    "                clustered_responses[category][level][label].append(paths[idx])\n",
    "\n",
    "            # **Plot Clusters**\n",
    "            sns.scatterplot(\n",
    "                x=reduced_embeddings[:, 0], \n",
    "                y=reduced_embeddings[:, 1], \n",
    "                hue=cluster_labels,  \n",
    "                palette=\"deep\",  \n",
    "                ax=ax, alpha=0.7, s=50  \n",
    "            )\n",
    "\n",
    "            ax.set_xlabel(\"UMAP Component 1\")\n",
    "            ax.set_ylabel(\"UMAP Component 2\")\n",
    "            ax.set_title(f\"{category.capitalize()} Paths - Difficulty {level}\")\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print Clustered Responses for Both Correct & Incorrect Paths**\n",
    "for category in [\"correct\", \"incorrect\"]:\n",
    "    print(f\"\\n### Clustered {category.capitalize()} Responses ###\\n\")\n",
    "    for level, clusters in clustered_responses[category].items():\n",
    "        print(f\"\\n### Difficulty {level} ###\\n\")\n",
    "        for cluster_id, responses in clusters.items():\n",
    "            print(f\"\\n--- Cluster {cluster_id} ---\\n\")\n",
    "            for response in responses[:3]:  # Print up to 3 examples per cluster\n",
    "                print(response)\n",
    "                print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I got an idea to see what the entropy does for each word in the CoT after thinking about the entropy for clusters in the UMAP plot, so I went ahead and looked at the word wise entropy split by difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import umap\n",
    "from scipy.stats import entropy\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load embedding model\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def get_embeddings(paths):\n",
    "    \"\"\"Generates embeddings for a list of paths.\"\"\"\n",
    "    if not paths:\n",
    "        return np.array([])  # Return empty array if no paths available\n",
    "    return np.array(embedder.encode(paths, convert_to_numpy=True))\n",
    "\n",
    "def compute_wordwise_entropy(paths):\n",
    "    \"\"\"\n",
    "    Computes entropy at each word of CoT to measure randomness in reasoning.\n",
    "\n",
    "    Parameters:\n",
    "    - paths (list of list of str): Multiple CoT responses split into words.\n",
    "\n",
    "    Returns:\n",
    "    - List of entropy values per word.\n",
    "    \"\"\"\n",
    "    max_words = max(len(path) for path in paths)\n",
    "    wordwise_distributions = [{} for _ in range(max_words)]\n",
    "\n",
    "    for path in paths:\n",
    "        for word_idx, word in enumerate(path):\n",
    "            wordwise_distributions[word_idx][word] = wordwise_distributions[word_idx].get(word, 0) + 1\n",
    "\n",
    "    entropy_scores = []\n",
    "    for word_dist in wordwise_distributions:\n",
    "        probs = np.array(list(word_dist.values())) / sum(word_dist.values()) if word_dist else np.array([1])\n",
    "        entropy_scores.append(entropy(probs))\n",
    "\n",
    "    return entropy_scores  # Return entropy per word\n",
    "\n",
    "def remove_word_outliers(word_counts):\n",
    "    \"\"\"\n",
    "    Removes outliers from word numbers using the IQR method.\n",
    "\n",
    "    Parameters:\n",
    "    - word_counts (list of int): List of word numbers.\n",
    "\n",
    "    Returns:\n",
    "    - int: Upper bound for word numbers after removing outliers.\n",
    "    \"\"\"\n",
    "    q1 = np.percentile(word_counts, 25)\n",
    "    q3 = np.percentile(word_counts, 75)\n",
    "    iqr = q3 - q1\n",
    "    upper_bound = q3 + 1.5 * iqr  # Define outlier threshold\n",
    "\n",
    "    return int(min(upper_bound, max(word_counts)))  # Ensure within max word range\n",
    "\n",
    "# Generate Embeddings for Correct and Incorrect Paths by Difficulty**\n",
    "correct_embeddings_by_difficulty = {}\n",
    "wrong_embeddings_by_difficulty = {}\n",
    "correct_wordwise_entropy = {}\n",
    "wrong_wordwise_entropy = {}\n",
    "\n",
    "word_lengths = []  # Track word lengths to filter outliers\n",
    "\n",
    "for level in range(1, 6):\n",
    "    correct_paths = correct_paths_by_difficulty[level]\n",
    "    wrong_paths = wrong_paths_by_difficulty[level]\n",
    "\n",
    "    correct_embeddings_by_difficulty[level] = get_embeddings(correct_paths)\n",
    "    wrong_embeddings_by_difficulty[level] = get_embeddings(wrong_paths)\n",
    "\n",
    "    # Compute wordwise entropy for correct and incorrect paths\n",
    "    correct_wordwise_entropy[level] = compute_wordwise_entropy(correct_paths)\n",
    "    wrong_wordwise_entropy[level] = compute_wordwise_entropy(wrong_paths)\n",
    "\n",
    "    # Track word lengths for outlier removal\n",
    "    word_lengths.extend([len(path) for path in correct_paths])\n",
    "    word_lengths.extend([len(path) for path in wrong_paths])\n",
    "\n",
    "# Remove Outliers from word Number (X-Axis)**\n",
    "max_valid_words = remove_word_outliers(word_lengths)\n",
    "\n",
    "# Create Separate wordwise Entropy Plots Per Difficulty Level**\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))  # 2 Rows, 3 Columns\n",
    "axes = axes.flatten()\n",
    "\n",
    "for level in range(1, 6):\n",
    "    ax = axes[level - 1]  # Select subplot\n",
    "\n",
    "    if level in correct_wordwise_entropy and level in wrong_wordwise_entropy:\n",
    "        correct_entropy_per_word = correct_wordwise_entropy[level][:max_valid_words]\n",
    "        incorrect_entropy_per_word = wrong_wordwise_entropy[level][:max_valid_words]\n",
    "\n",
    "        ax.plot(range(1, len(correct_entropy_per_word) + 1), correct_entropy_per_word, linestyle=\"-\", color=\"green\", label=\"Correct Paths\")\n",
    "        ax.plot(range(1, len(incorrect_entropy_per_word) + 1), incorrect_entropy_per_word, linestyle=\"--\", color=\"red\", label=\"Incorrect Paths\")\n",
    "\n",
    "        ax.set_xlabel(\"Word Index\")\n",
    "        ax.set_ylabel(\"Entropy (Wordwise Randomness)\")\n",
    "        ax.set_title(f\"Wordwise Entropy Trends (Difficulty {level})\")\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "\n",
    "# Remove last empty subplot (for 2x3 layout)\n",
    "fig.delaxes(axes[-1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.xlim(1, max_valid_words)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
